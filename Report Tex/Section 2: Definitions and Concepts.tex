\section{Definitions and Concepts}

\subsection{Numerical Methods}
\par \term{Numerical methods} are techniques used to approximate solutions to problems that cannot be solved exactly.\\
Numerical methods are prevalent when working with problems of differential calculus in a computational context, where many problems do not have closed-form solutions.\\
A numerical method can be interpreted as an alogorithm; a series of steps that can be followed to approximate a solution.\\
Many numerical methods exist, each with their own properties and tradeoffs.\\
In this respect, different methods may be more or less suitable for different problems.\\
Core to understanding which to use for a particular problem are the concepts of \term{error} and \term{stability}.\\
Before discussing these properties, however, we must understand how a numerical method works.\\
The basis of many numerical methods is the concept of a \term{time step}.

\subsection{Time Steps}
Let's take a step back to when we first studied derivatives.\\
\term{Newton's Difference Quotient} should be familiar: 
$f'(x) = \Lim{h \to 0} \frac{f(x+h) - f(x)}{h}$

\par Viewing Newton's Difference Quotient in the context of numerical methods, we call $h$ a \term{time step}.\\
Due to computational constraints, we cannot take $h$ to be infinitesimal. (A computer's memory is as small as it is big)\\
Instead, we take $h$ to be a small, finite number.\\
This defines the concept of a \term{step size}.\\

\par For numerical methods, we use $y(t)$ to denote the solution to a differential equation at time $t$.\\
We approximate $y'(t)$ by $\frac{y(t+h) - y(t)}{h}$ using Newton's Difference Quotient.\\
Note this is an approximation because we have dropped the limit; $h$ is not infinitesimal.\\
This gives $y(t + h) \approx y(t) + h y'(t)$; a first-order approximation of $y$ a small time step $h$ in the future.\\
For a numerical method we say $y(t + h) = y(t) + h y'(t)$ 

\subsection{Error}
\par In numerical analysis, \term{error} is the difference between the numerical solution and the exact solution to a problem.\\
Error can be caused by many factors, such as the choice of numerical method, the choice of time step, or the precision of the computer.\\
Error can be classified into two categories: truncation error and rounding error.\\
\term{Truncation Error} is the error introduced by approximating a problem, such as using a finite time step.\\
\term{Rounding Error} is the error introduced by the finite precision of a computer.\\
Error is a crucial concept in numerical analysis, as it determines the accuracy of a numerical method.\\
Any error mentioned in this document refers to the truncation error; we won't be looking at how comupters run these calculations and the rounding errors that come with it.

\subsection{Stability}
\par In numerical analysis, a method is said to be \term{stable} if small deviations in the input do not lead to large perturbtions in the output.
In the context of differential equations, a method is said to be stable if the solution does not grow to be unbounded as the number of time steps increases. (This, of course, only applies if the exact solution is bounded. We will restrict ourselves to this with our analysis.)

\par When solving differential equations numerically, the choice of time step is crucial.
If the step size is too large, the solution may become unstable; the numerical solution will diverge from the analytic solution in proportion with the number of steps.
If the step size is too small, the solution may be accurate and stable, but the computation may be too slow.

\par The tradeoff between error, stability and compute is a common theme in numerical analysis.\\
The sweet spot for maximal efficiency depends entirely on the choice of numerical method.\\
This marks the core motivation for this report; solidifying an understanding to better inform the choice of method and step size for a given problem.

%\subsection{Complex-Variable Method}
%Take a function $f: \bR \longrightarrow \bR,\; x \longmapsto f(x)$.\\
%Let $f$ be \term{holomorphic} on its domain: $f$ is complex differentiable in a neighbourhood of any $x \in \bR$.\\
%$\forall x$, $f$ is complex differentiable on $B_{\beta}(x) = \{z \in \bC \,|\, |z|-|x| < \beta_{_{\text{small}}}\}$ for some $\beta_{_{\text{small}}} > 0$.\\
%In this case, we get the following fact:\\
%\[f'(x) = \frac{Im\big(f(x+ih)\big)}{h} + O(h^2), \quad \text{where}\; h \in \bR \;\text{and}\; h \neq 0\]\\

%\par Combining this with the first order approximation above, we get $y(t + \Delta_t) \approx y(t) + Im\big(y(t+i\Delta_t)\big)$.

%TODO: Flesh this out more!
